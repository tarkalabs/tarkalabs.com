{"hash":"befc11b432811bca2258a5ed9ac12568bf4c1023","data":{"caseStudy":{"id":"a1687c62856896cb97bbb0a82bc0f6d7","title":"Tunecore","clientId":9,"bannerText":"Scaling Royalty Payouts for Music Distribution Platforms","tech":"go, aws","content":"<h1 id=\"overview\"><a href=\"#overview\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Overview</h1>\n<p>In the music distribution world, it’s not just about getting tracks onto DSPs. Once\nstreams start coming in, platforms take on the complex responsibility of making\nsure royalties reach the right artists and rights holders. One of our clients, a fast-\ngrowing music distributor, was handling this well until the scale started to grow.\nTheir existing system worked fine at lower volumes, but as the monthly royalty\ndata crossed hundreds of millions of records, it began to slow down significantly.\nProcessing delays increased, technical overhead piled up, and it became clear that\nthe architecture needed a rethink to keep up with growth.\nThey needed a faster and more reliable way to scale.</p>\n<h1 id=\"challenges\"><a href=\"#challenges\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Challenges</h1>\n<p>As we dug into the system, several underlying issues came to light, most of them\nhidden during earlier stages of development but now impossible to ignore. The\narchitecture was beginning to show strain across multiple fronts. Some of the\nmajor Challenges involved:</p>\n<p>• Processing raw royalty data with hundreds of millions of rows each month</p>\n<p>• Managing duplicate ISRCs and inconsistent metadata from multiple DSPs</p>\n<p>• Legacy codebase that became harder to maintain and debug over time</p>\n<p>• Slow processing cycles that stretched into days, with no clear visibility into when they would finish\n• Heavy load on the database, with both reads and writes competing for resources</p>\n<p>• Frustrated users due to unreliable performance and sluggish reporting interfaces</p>\n<p>• Limited observability and metrics — scaling meant throwing more infrastructure at the problem without fixing the root issues</p>\n<h1 id=\"research\"><a href=\"#research\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Research</h1>\n<p>As part of the re-architecture e ff ort, we spent time researching not just how to\nhandle the current scale, but also how to ensure the system could grow with us\nover the next few years without needing a complete overhaul again. The existing\nsetup was built in Ruby with heavy use of MariaDB stored procedures, which had\nbecome a bottleneck. Reporting and analytics were running on the same database\nthat handled processing, leading to contention and major slowdowns.</p>\n<p>There was no batching or parallelism in place, which meant everything was\nprocessed in a single thread further compounding the delays. W e explored a\nrange of options: di ff erent batching techniq ues, caching strategies, and even\nalternative languages. But our goal wasn' t just performance we also wanted to\nmake sure the system was something the current team could support and evolve.\nSo, instead of bringing in a completely new stack, we focused on technologies and\npatterns that were powerful but still within reach of the team' s comfort z one.</p>\n<h1 id=\"our-approach\"><a href=\"#our-approach\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Our approach</h1>\n<h2 id=\"rebuilding-the-ingestion-engine\"><a href=\"#rebuilding-the-ingestion-engine\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Rebuilding the Ingestion Engine</h2>\n<p>We replaced the existing Ruby based ingestion pipeline with a G olang (something\nthe client team was already comfortable with, which made long-term\nmaintainability much easier) parallel processing pipeline that handled records in\nbatches of 50,000. This was combined with <strong>PebbleDB</strong>, a lightweight embedded\nkey-value store to perform fast local lookups without the memory bloat or\nnetwork latency of Redis.</p>\n<p>To handle real-world issues like duplicate ISRCs, we customized our storage logic\nto allow multiple values per key. This ensured accurate matching even when DSP\ndata was inconsistent.</p>\n<h2 id=\"rethinking-the-data-pipeline\"><a href=\"#rethinking-the-data-pipeline\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Rethinking the Data Pipeline</h2>\n<p>CSV imports into MariaDB were taking hours and failing often. We moved\ningestion to ClickHouse, bringing load time for 500 million records down to about\n10 minutes from existing 4 hours. We then used ClickHouse for aggregation and\nS3 integration, sending only the critical summary data to MariaDB for\ntransactional operations.</p>\n<p>On the frontend, we replaced the read-heavy reporting tables with denormalized\nClickHouse views. This dramatically improved U I responsiveness and made\nfiltering fast and smooth for end users.</p>\n<h1 id=\"outcome\"><a href=\"#outcome\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Outcome</h1>\n<p>• Processing time dropped by over 95% , all without increasing infrastructure costs.</p>\n<p>• The system now comfortably handles over 500 million records per month with ability to scale further.</p>\n<p>• Even with messy metadata and duplicate ISRCs, payouts remained accurate and traceable.</p>\n<p>• A hybrid ClickHouse + MariaDB setup gave us the best of both worlds—speed for analytics and integrity for transactions.</p>\n<p>• On the frontend, users saw a massive boost in responsiveness, with near-instant filtering and reporting.</p>\n"},"clients":{"edges":[{"node":{"id":"36","name":"Music Distribution Company","style":"electricIndigo","logo":""}},{"node":{"id":"35","name":"Global Record Label","style":"fullBlack","logo":""}},{"node":{"id":"34","name":"Starz","style":"dark-blue","logo":""}},{"node":{"id":"33","name":"FamilyCloud","style":"electricIndigo","logo":""}},{"node":{"id":"32","name":"Redacted","style":"fullBlack","logo":""}},{"node":{"id":"31","name":"Redacted","style":"pricebook-orange","logo":""}},{"node":{"id":"30","name":"Redacted","style":"electricIndigo","logo":""}},{"node":{"id":"29","name":"AGS","style":"red","logo":""}},{"node":{"id":"28","name":"Redacted","style":"green","logo":""}},{"node":{"id":"27","name":"Hotstar","style":"fullBlack","logo":"org/hotstar.png"}},{"node":{"id":"26","name":"Framework","style":"fullBlack","logo":"org/framework.svg"}},{"node":{"id":"25","name":"Routinr","style":"purple-blue","logo":"org/routinr.svg"}},{"node":{"id":"24","name":"eVisitNB","style":"red","logo":""}},{"node":{"id":"23","name":"EquipmentFX","style":"yellow","logo":""}},{"node":{"id":"22","name":"Beatclub","style":"dark-grey","logo":"org/beatclub.svg"}},{"node":{"id":"21","name":"Social Lab","style":"yellow","logo":""}},{"node":{"id":"20","name":"IFAD","style":"yellow","logo":""}},{"node":{"id":"19","name":"10i Commerce","style":"dark-blue","logo":""}},{"node":{"id":"18","name":"IDExcel","style":"grey","logo":""}},{"node":{"id":"17","name":"Aisle","style":"green","logo":""}},{"node":{"id":"16","name":"Trazaar","style":"yellow","logo":""}},{"node":{"id":"15","name":"Jiffle Now","style":"pink","logo":""}},{"node":{"id":"14","name":"Farmstead","style":"green","logo":""}},{"node":{"id":"13","name":"Inkl","style":"dark-blue","logo":""}},{"node":{"id":"12","name":"Glydel","style":"grey","logo":""}},{"node":{"id":"11","name":"Messaging Solution Provider","style":"black","logo":""}},{"node":{"id":"10","name":"EAM360","style":"eam-blue","logo":"org/eam360.svg"}},{"node":{"id":"9","name":"TuneCore","style":"black","logo":""}},{"node":{"id":"8","name":"Abridge","style":"orange","logo":""}},{"node":{"id":"7","name":"GE Digital Services","style":"green","logo":""}},{"node":{"id":"6","name":"Gaea Global","style":"red","logo":""}},{"node":{"id":"5","name":"Genetic Direction","style":"dark-blue","logo":""}},{"node":{"id":"4","name":"IDEO","style":"yellow","logo":""}},{"node":{"id":"3","name":"Fankave","style":"black","logo":""}},{"node":{"id":"2","name":"Caratlane","style":"blue","logo":""}},{"node":{"id":"1","name":"Modus","style":"pink","logo":""}}]}},"context":{}}