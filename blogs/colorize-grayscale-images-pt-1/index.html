<!DOCTYPE html>
<html data-html-server-rendered="true" lang="en" data-vue-tag="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D">
  <head>
    <title>Part I — Creating a neural network using tensorflow to colorize grayscale images. · Tarka Labs - Tarka Labs</title><meta name="gridsome:hash" content="f6fa4d08b23fbd735401f414f27e460c04f21e9d"><meta data-vue-tag="ssr" charset="utf-8"><meta data-vue-tag="ssr" name="generator" content="Gridsome v0.7.23"><meta data-vue-tag="ssr" data-key="viewport" name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover"><meta data-vue-tag="ssr" data-key="format-detection" name="format-detection" content="telephone=no"><meta data-vue-tag="ssr" name="viewport" content="width=device-width, initial-scale=1.0"><meta data-vue-tag="ssr" property="og:title" content="Part I — Creating a neural network using tensorflow to colorize grayscale images. · Tarka Labs"><meta data-vue-tag="ssr" property="og:description" content="Part I — Creating a neural network using tensorflow to colorize grayscale images"><meta data-vue-tag="ssr" property="og:image" content="/assets/img/default-cover.55254b66.png"><meta data-vue-tag="ssr" property="og:image:height" content="627"><meta data-vue-tag="ssr" property="og:image:width" content="1200"><link data-vue-tag="ssr" rel="icon" href="data:,"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="16x16" href="/assets/static/favicon.ce0531f.92f6d0f06feb6aec5e019521ff224fd8.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="32x32" href="/assets/static/favicon.ac8d93a.92f6d0f06feb6aec5e019521ff224fd8.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="96x96" href="/assets/static/favicon.b9532cc.92f6d0f06feb6aec5e019521ff224fd8.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="76x76" href="/assets/static/favicon.f22e9f3.92f6d0f06feb6aec5e019521ff224fd8.png"><link rel="preload" href="/assets/css/0.styles.ff22d50a.css" as="style"><link rel="preload" href="/assets/js/app.5034332d.js" as="script"><link rel="preload" href="/assets/js/page--src--templates--blog-vue.80bca3bd.js" as="script"><link rel="stylesheet" href="/assets/css/0.styles.ff22d50a.css"><noscript data-vue-tag="ssr"><style>.g-image--loading{display:none;}</style></noscript>
    <meta
      name="google-site-verification"
      content="j7cLUK-kxGEpMOY7valSkamH4kQe_l38yMMAXbpk19U"
    />
    <noscript>
      <div class="noscript-container">
        <a href="/" class="noscript-logo">Tarka <br />_Labs</a>
        <div class="noscript-text-container">
          <h1>Uh oh! Looks like <span>JavaScript</span> is disabled.</h1>
          <p>
            Bitman requires <span>JavaScript</span> to fuel his thirst to end
            bad UX and lazy design, which is necessary to give you the best
            viewing experience possible. Please enable it to continue to our
            website.
          </p>
        </div>
      </div>
    </noscript>
  </head>

  <body >
    <div><div id="app" data-server-rendered="true" data-v-b5a9baaa><div data-v-b5a9baaa><div id="banner-section" data-v-b5a9baaa><div class="banner" style="background:;display:none;" data-v-b5a9baaa><div class="layout" data-v-b5a9baaa><div data-v-b5a9baaa></div><div class="hero heading-size-5" style="color:#ffffff;" data-v-b5a9baaa></div><div data-v-b5a9baaa></div></div></div><div data-v-b5a9baaa></div></div><div class="sidebar" data-v-d6d2017e data-v-b5a9baaa><div class="nav" data-v-d6d2017e><div class="fixed" data-v-d6d2017e><a href="/" data-v-9b1a4c9c data-v-d6d2017e> TARKA<br data-v-9b1a4c9c>_LABS </a><div class="menu" data-v-50705736 data-v-d6d2017e><div class="control" style="stroke:black;" data-v-50705736><div class="spinner heading-size-9" data-v-02ea7230 data-v-50705736><span class="side-menu-symbol" data-v-02ea7230><span class="menu-symbol rotate180t90" data-v-02ea7230><svg height="10" width="10" data-v-02ea7230><line x1="0" y1="5" x2="10" y2="5" style="stroke-width: 2" data-v-02ea7230></line></svg></span><span class="menu-symbol rotate90t0" data-v-02ea7230><svg height="10" width="10" data-v-02ea7230><line x1="0" y1="5" x2="10" y2="5" style="stroke-width: 2" data-v-02ea7230></line></svg></span></span><span style="vertical-align: middle" data-v-02ea7230> menu </span></div><div class="active-page body-jetbrains-size-11 fade-in" data-v-128e5feb data-v-50705736>
  
</div></div><div class="items hidden" data-v-50705736><ul class="main-nav" data-v-244aa462 data-v-50705736><div class="primary fadeOut sidebar" data-v-244aa462><li data-v-244aa462><a href="/music-biz" data-v-244aa462>/MusicBiz</a></li><li data-v-244aa462><a href="/genai" data-v-244aa462>/GenAI</a></li><li data-v-244aa462><a href="https://solutions.tarkalabs.com/design/" target="_self" data-v-244aa462>/Design</a></li><li data-v-244aa462><a href="/develop" data-v-244aa462>/Develop</a></li><li data-v-244aa462><a href="/case-studies" data-v-244aa462>
        /Case_Studies
      </a></li><li data-v-244aa462><a href="/careers" data-v-244aa462>/Careers</a></li><li data-v-244aa462><a href="/about" data-v-244aa462>/About</a></li><li data-v-244aa462><a href="/contact" data-v-244aa462>/Contact</a></li></div></ul><ul class="sub body-jetbrains-size-11 fadeOut sidebar" data-v-3cc3824e data-v-50705736><li data-v-3cc3824e><a href="/blogs" class="active" data-v-3cc3824e>/blogs</a></li><li data-v-3cc3824e><a href="/talks" data-v-3cc3824e>/talks</a></li><li data-v-3cc3824e><a href="/train" data-v-3cc3824e>/train</a></li></ul></div></div><a href="/contact" class="heading-size-9" data-v-573e12d8 data-v-d6d2017e>
  Get in<br data-v-573e12d8>touch<span class="arrow" data-v-573e12d8>-&gt;</span></a></div></div><!----></div><div class="baseLayout" data-v-996dafb6 data-v-b5a9baaa><div data-v-996dafb6></div><div data-v-996dafb6><div class="blog-details-page" data-v-996dafb6><div class="inner-section" data-v-996dafb6><p class="heading-size-10 capitalize" data-v-996dafb6>
        /AI - 4 min read
      </p><h1 class="title" data-v-996dafb6>Part I — Creating a neural network using tensorflow to colorize grayscale images.</h1><div class="author-basic-info" data-v-996dafb6><img src="/assets/img/bitman.9f5fc4e7.png" alt="Deepak Prasanna" width="64" data-v-996dafb6><div data-v-996dafb6><p class="heading-size-9 capitalize" data-v-996dafb6>Deepak Prasanna</p><p class="body-jetbrains-size-10" data-v-996dafb6>
            A tarkan
          </p></div></div></div><img src="/assets/img/default-cover.55254b66.png" alt="" class="header-img" data-v-996dafb6><div class="toc-wrapper" data-v-996dafb6><h2 class="heading-size-7" data-v-996dafb6>Table of contents</h2><div class="toc" data-v-996dafb6><a href="#content" class="heading-size-9 heading" data-v-996dafb6><p data-v-996dafb6>/01</p><p data-v-996dafb6>Intro</p></a><a href="#toc-section-1" class="heading-size-9 heading" data-v-996dafb6><p data-v-996dafb6>/02</p><p data-v-996dafb6>Choosing the DATASET</p></a><a href="#toc-section-2" class="heading-size-9 heading" data-v-996dafb6><p data-v-996dafb6>/03</p><p data-v-996dafb6>Exploring the DATA</p></a></div></div><div id="content" class="content" data-v-996dafb6><p>This is the first article that I am writing in the efforts to create a neural network that will colorize a grayscale image. The idea itself is pretty straight forward, if were to break it into steps this is how I would.</p>
<ol>
<li>Take images from a colorized dataset like <a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="nofollow noopener noreferrer">cifar10</a> or <a href="http://places.csail.mit.edu/" target="_blank" rel="nofollow noopener noreferrer">places</a>.</li>
<li>Generate the equivalent grayscale image for every image in the dataset.</li>
<li>For training use the grayscale image as input and use the colorized image as output.</li>
<li>When the network converges, feed in a random image to see how the model colorizes it.</li>
</ol>
<p>I will be pushing my code here <a href="https://github.com/deepakprasanna/tfcolorize" target="_blank" rel="nofollow noopener noreferrer">https://github.com/deepakprasanna/tfcolorize</a></p>
<h1 id="toc-section-1"><a href="#choosing-the-dataset" aria-hidden="true"><span class="icon icon-link"></span></a>Choosing the DATASET</h1>
<p>In this part of the series, I will be focusing on the data preparation part. I will be using <a href="https://github.com/CSAILVision/miniplaces" target="_blank" rel="nofollow noopener noreferrer">miniplaces</a> dataset which is a subset of the places dataset. You can read more about the dataset on the repo’s README page.</p>
<p>After you download and extract the dataset, you will see the data is split into different categories and the categories themselves are arranged alphabetically.</p>
<img src="/blog/colorize-grayscale-images-pt-1/1.webp">
<h1 id="toc-section-2"><a href="#exploring-the-data" aria-hidden="true"><span class="icon icon-link"></span></a>Exploring the DATA</h1>
<p>I will be using opencv to read the image and get the RGB values of each pixel as a numpy array. Thankfully opencv also has an easy way to read the grayscale version of the image. Let’s use cv2 to open the same image in both grayscale and RGB mode.</p>
<div class="gridsome-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> cv2
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token operator">%</span>matplotlib inlinegimg <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">'00000001.jpg'</span><span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>IMREAD_GRAYSCALE<span class="token punctuation">)</span>
cimg <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">'00000001.jpg'</span><span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>IMREAD_COLOR<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>gimg<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>cimg<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
<span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span></code></pre></div>
<p>In the above code, I have used <code class="language-inline-text">cv2.imread</code> to read the same image in both grayscale and colormode. And I have store them in the variables <code class="language-inline-text">gimg</code> and <code class="language-inline-text">cimg</code> respectively. Before we get into more details just remember all images in the places dataset is of resolution 128x128.</p>
<p>In the above code, when we used opencv to read the image in grayscale mode, it returned a numpy array of shape 128x128, because grayscale images contain only a single channel. This means we have got one value for every pixel.</p>
<p>On the otherhand, since the colorized image has three channels RGB, cv2 has returned an array of shape 128x128x3. This means we have got 3 values, one for R, one for G and one for B for every pixel.</p>
<p>We can use <code class="language-inline-text">plt.imshow</code> to visualize the image from this numpy array.</p>
<p>Before we proceed to the next step, we must reshape this data such that the shapes of the grayscale and RGB images are like below:</p>
<ul>
<li>grayscale — 1x128x128.</li>
<li>coloredimage — 3x128x128.
​</li>
</ul>
<div class="gridsome-highlight" data-language="python"><pre class="language-python"><code class="language-python">gimg_reshaped <span class="token operator">=</span> np<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>gimg<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre></div>
<p>​
Its always good to quickly check if your reshaping has done any damage to the data. Since <code class="language-inline-text">gimg_reshaped</code> has only one channel we can plot the first channel alone to see how it looks.</p>
<img src="/blog/colorize-grayscale-images-pt-1/2.webp">
<p>Let’s now reshape the colored image.</p>
<div class="gridsome-highlight" data-language="python"><pre class="language-python"><code class="language-python">cimg_reshaped <span class="token operator">=</span> np<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>cimg<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre></div>
<p>Let’s plot this reshaped data to check.</p>
<img src="/blog/colorize-grayscale-images-pt-1/3.webp">
<p>You can see that reshape has completely ruined the data. A couple of google searches led me to this <a href="https://github.com/keras-team/keras/issues/315#issuecomment-215814534" target="_blank" rel="nofollow noopener noreferrer">link</a>.</p>
<p>Let’s change this reshape statement as suggested in this link.</p>
<div class="gridsome-highlight" data-language="python"><pre class="language-python"><code class="language-python">cimg_reshaped <span class="token operator">=</span> np<span class="token punctuation">.</span>swapaxes<span class="token punctuation">(</span>np<span class="token punctuation">.</span>swapaxes<span class="token punctuation">(</span>cimg<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span></code></pre></div>
<img src="/blog/colorize-grayscale-images-pt-1/4.webp">
<p>Finally we are now able to reshape the data like we expected and visualize individual channels without disturbing the data.</p>
<p>In the next part I will be creating a grayscale equivalent for all the images in the dataset and I will be writing a <code class="language-inline-text">getbatch</code> function.</p>
</div><hr data-v-996dafb6><div class="inner-section" data-v-996dafb6><div class="author-basic-info" data-v-996dafb6><img src="/assets/img/bitman.9f5fc4e7.png" alt="Deepak Prasanna" width="64" data-v-996dafb6><div data-v-996dafb6><p class="heading-size-9 capitalize" data-v-996dafb6>Deepak Prasanna</p><p class="body-jetbrains-size-10" data-v-996dafb6>
            A tarkan
          </p></div></div><p class="body-opensans-size-9" data-v-996dafb6></p><div class="social-links" data-v-996dafb6><!----><!----><a href="https://medium.com/@deepakprasanna" target="_blank" class="heading-size-9" data-v-996dafb6>
          Medium
        </a></div></div><hr data-v-996dafb6><div class="related-articles" data-v-996dafb6><div class="flex-space-between" data-v-996dafb6><p class="heading-size-7" data-v-996dafb6>_related articles</p><a href="/blogs" class="heading-size-9 underline" data-v-996dafb6>View all</a></div><div class="flex-space-between blog-card-wrapper" data-v-996dafb6><a href="/blogs/extracting-structured-data" class="blog-card" data-v-996dafb6><img src="/assets/img/default-cover.55254b66.png" alt="Extracting Structured Data from PDFs with Claude Sonnet and Amazon Bedrock" class="thumbnail" data-v-996dafb6><div class="info" data-v-996dafb6><p class="heading-size-10 capitalize" data-v-996dafb6>/AI</p><h3 data-v-996dafb6>Extracting Structured Data from PDFs with Claude Sonnet and Amazon Bedrock</h3><p class="body-jetbrains-size-10" data-v-996dafb6>
              Kesavan   7 min read
            </p></div></a><a href="/blogs/batch-transcription" class="blog-card" data-v-996dafb6><img src="/assets/img/batch-transcription.e03c0d91.webp" alt="Implementing Serverless Batch Transcription with AWS Step Functions and Azure AI Services" class="thumbnail" data-v-996dafb6><div class="info" data-v-996dafb6><p class="heading-size-10 capitalize" data-v-996dafb6>/AI</p><h3 data-v-996dafb6>Implementing Serverless Batch Transcription with AWS Step Functions and Azure AI Services</h3><p class="body-jetbrains-size-10" data-v-996dafb6>
              Kesavan   8 min read
            </p></div></a></div></div><div class="lets-talk" data-v-188e6a71><div class="message heading-size-7" data-v-188e6a71>
    Let’s build digital solutions together.
  </div><div class="action-container" data-v-188e6a71><div class="action-button heading-size-5" data-v-188e6a71><div data-v-188e6a71>Get in touch</div><div class="arrow" data-v-188e6a71>-&gt;</div></div><img src="/assets/img/talk.71d1d2f3.svg" alt="Lenny Face" data-v-188e6a71></div></div></div></div><div data-v-996dafb6></div></div><div id="footer" class="baseLayout" data-v-996dafb6 data-v-b5a9baaa><div data-v-996dafb6></div><div data-v-996dafb6><div class="site-footer" data-v-0a037a4b data-v-b5a9baaa><ul class="main-nav footer" data-v-244aa462 data-v-0a037a4b><div class="primary fadeIn" data-v-244aa462><li data-v-244aa462><a href="/music-biz" data-v-244aa462>/MusicBiz</a></li><li data-v-244aa462><a href="/genai" data-v-244aa462>/GenAI</a></li><li data-v-244aa462><a href="https://solutions.tarkalabs.com/design/" target="_self" data-v-244aa462>/Design</a></li><li data-v-244aa462><a href="/develop" data-v-244aa462>/Develop</a></li><li data-v-244aa462><a href="/case-studies" data-v-244aa462>
        /Case_Studies
      </a></li><li data-v-244aa462><a href="/careers" data-v-244aa462>/Careers</a></li><li data-v-244aa462><a href="/about" data-v-244aa462>/About</a></li><li data-v-244aa462><a href="/contact" data-v-244aa462>/Contact</a></li></div></ul><div class="subnav" data-v-0a037a4b><ul class="sub body-jetbrains-size-11 footer fadeIn" data-v-3cc3824e data-v-0a037a4b><li data-v-3cc3824e><a href="/blogs" class="active" data-v-3cc3824e>/blogs</a></li><li data-v-3cc3824e><a href="/talks" data-v-3cc3824e>/talks</a></li><li data-v-3cc3824e><a href="/train" data-v-3cc3824e>/train</a></li></ul><div data-v-fae945d8 data-v-0a037a4b><a href="https://twitter.com/tarkalabs" target="_blank" rel="noopener" class="external" data-v-fae945d8>Twitter</a><a href="https://in.linkedin.com/company/tarka-labs" target="_blank" rel="noopener" class="external" data-v-fae945d8>LinkedIn</a></div><div class="sedin" data-v-0a037a4b><a href="https://sedintechnologies.com/" target="_blank" rel="noopener" class="external" data-v-0a037a4b>Tarka Labs is a division of Sedin Technologies</a></div></div></div></div><div data-v-996dafb6></div></div></div></div></div>
    <script src="/assets/js/app.5034332d.js" defer></script><script src="/assets/js/page--src--templates--blog-vue.80bca3bd.js" defer></script><script data-vue-tag="ssr" src="https://unpkg.com/@lottiefiles/lottie-player@0.4.0/dist/lottie-player.js" data-body="true"></script>
  </body>
</html>
